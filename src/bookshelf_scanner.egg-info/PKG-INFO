Metadata-Version: 2.4
Name: bookshelf-scanner
Version: 1.0.0
Summary: Scan bookshelves and export to Goodreads/StoryGraph
License: MIT
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: ultralytics>=8.0.0
Requires-Dist: transformers<5.0.0,>=4.40.0
Requires-Dist: torch>=2.0.0
Requires-Dist: torchvision>=0.15.0
Requires-Dist: pillow>=10.0.0
Requires-Dist: einops>=0.7.0
Requires-Dist: pyvips-binary==8.16.0
Requires-Dist: pyvips==2.2.3
Requires-Dist: requests>=2.31.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: typer[all]>=0.9.0
Requires-Dist: rich>=13.0.0
Requires-Dist: flask>=3.0.0
Requires-Dist: flask-cors>=4.0.0
Provides-Extra: gpu
Requires-Dist: accelerate>=0.25.0; extra == "gpu"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"

# Bookshelf Scanner

Scan photos of your bookshelf and export to Goodreads or StoryGraph.

## Features

- **Automatic spine detection** using YOLO object detection
- **Text extraction** using Moondream 0.5B vision-language model
- **Metadata lookup** via Google Books API
- **Goodreads-compatible CSV export** for easy import

## Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/bookshelf-scanner
cd bookshelf-scanner

# Install dependencies
pip install -e .

# Or with GPU support
pip install -e ".[gpu]"
```

## Quick Start

```bash
# Extract title/author from a single spine image
python -m bookshelf_scanner.extractor data/spine.jpg

# Process a directory of spine crops and write CSV output
python -m bookshelf_scanner.extractor outputs/detections/my_shelf_crops --output outputs/extractions/my_shelf.csv

# Run in offline mode using only locally cached model files
python -m bookshelf_scanner.extractor outputs/detections/my_shelf_crops --local-files-only

# Look up extracted titles/authors in Google Books and write full API data to CSV
python -m bookshelf_scanner.lookup outputs/extractions/test.csv --output lookup_outputs.csv

# Run local Flask API for live webcam spine detection
python -m bookshelf_scanner.web_api --host 127.0.0.1 --port 5000
```

Set your API key in `secrets/.env`:

```bash
GOOGLE_BOOKS_API_KEY=your_google_books_api_key
```

## CLI Commands

### `python -m bookshelf_scanner.extractor`

Run Moondream extraction on one spine image or a directory of spine images.

```bash
python -m bookshelf_scanner.extractor INPUT [OPTIONS]
```

Arguments:

- `INPUT`: Path to a spine image file or a directory containing images.

Options:

- `--limit N`: Only process the first `N` images.
- `--output PATH`: Write extraction results to a CSV file.
- `--model-name NAME`: Model alias, Hugging Face repo ID, or local model path (default: `moondream-0.5b`).
- `--revision REV`: Model revision when loading from a repo.
- `--device DEVICE`: `auto`, `cpu`, `cuda`, or `mps` (default: `auto`).
- `--max-new-tokens N`: Max generated tokens per extraction (default: `100`).
- `--temperature FLOAT`: Decoding temperature (default: `0.1`).
- `--cache-dir PATH`: Optional Hugging Face model cache directory.
- `--modules-cache-dir PATH`: Cache directory for remote model Python modules (default: `.cache/huggingface/modules`).
- `--local-files-only`: Force offline mode and only use locally cached model files.

### `python -m bookshelf_scanner.lookup`

Look up extraction CSV rows (`title`/`author`) in Google Books and export all returned item fields to a CSV.

```bash
python -m bookshelf_scanner.lookup outputs/extractions/test.csv --output lookup_outputs.csv
```

Options:

- `--api-key KEY`: Override API key directly.
- `--env-file PATH`: Env file path for `GOOGLE_BOOKS_API_KEY` (default: `secrets/.env`).
- `--max-results N`: Results returned per title query (default: `5`).
- `--timeout N`: HTTP timeout in seconds (default: `10`).

### `python -m bookshelf_scanner.web_api`

Start a local Flask server for the webcam harness endpoint.

```bash
python -m bookshelf_scanner.web_api [OPTIONS]
```

Options:

- `--host HOST`: Bind address (default: `127.0.0.1`).
- `--port PORT`: Bind port (default: `5000`).
- `--model-path PATH`: YOLO model path (default: `yolov8n.pt` at repo root).
- `--confidence FLOAT`: Detector confidence threshold (default: `0.25`).
- `--iou-threshold FLOAT`: NMS IoU threshold (default: `0.45`).
- `--device DEVICE`: `auto`, `cpu`, `cuda`, `mps` (default: `auto`).
- `--classes CSV`: Comma-separated YOLO class IDs (default: `73` for books).

## Note on `bookshelf-scanner`

The packaged command `bookshelf-scanner scan ...` is currently a placeholder and not implemented yet. Use `python -m bookshelf_scanner.extractor ...` for the active CLI path.

## System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| Python | 3.10+ | 3.11+ |
| RAM | 4GB | 8GB |
| Storage | 2GB | 5GB |
| GPU | Not required | Any CUDA GPU |

## Configuration

Create a `config.yaml` file to customize settings:

```yaml
detection:
  confidence: 0.25
  device: auto

extraction:
  model: moondream-0.5b  # or moondream-2b for better accuracy
  device: auto

lookup:
  api_key: YOUR_GOOGLE_BOOKS_API_KEY  # optional

export:
  default_shelf: to-read
```

## Importing to Goodreads

1. Run extraction to produce your CSV, for example: `python -m bookshelf_scanner.extractor outputs/detections/my_shelf_crops --output outputs/extractions/my_shelf.csv`
2. Go to [Goodreads Import](https://www.goodreads.com/review/import)
3. Upload the generated CSV file
4. Review and confirm the imports

## License

MIT
